package processor

import (
	"context"
	"crypto/tls"
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"os"
	"strconv"
	"strings"
	"time"

	"cve-crawler/adapter/mongo"

	"github.com/artdarek/go-unzip"
	"github.com/go-resty/resty/v2"
	mg "gitlab.viettelcyber.com/awesome-threat/library/adapter/mongo"
	"gitlab.viettelcyber.com/awesome-threat/library/adapter/rabbit"
	"gitlab.viettelcyber.com/awesome-threat/library/clock"
	"gitlab.viettelcyber.com/awesome-threat/library/hash"
	"gitlab.viettelcyber.com/awesome-threat/library/log/pencil"
	"gitlab.viettelcyber.com/awesome-threat/library/rest"
	"go.mongodb.org/mongo-driver/bson"
	"golang.org/x/sync/errgroup"

	"cve-crawler/defs"
	"cve-crawler/model"
)

type cveCrawler struct {
	name    string
	context context.Context
	logger  pencil.Logger
	mongo   mongo.CrawlerRepository
	queue   rabbit.Service
	config  model.WorkerConfig
}

func newCveCrawler(ctx context.Context, conf model.WorkerConfig) Processor {
	logger, _ := pencil.New(defs.WorkerCveCrawler, pencil.DebugLevel, true, os.Stdout)
	worker := cveCrawler{name: defs.WorkerCveCrawler, context: ctx, logger: logger, config: conf}
	if worker.config.App.Timeout == 0 {
		worker.config.App.Timeout = defs.DefaultTimeout
	}
	if worker.config.App.Schedule == 0 {
		worker.config.App.Schedule = defs.DefaultSchedule
	}
	// Repository
	worker.mongo = mongo.NewCrawlerRepository(worker.config.Adapter.Mongo.Crawler)
	worker.queue = rabbit.NewService(worker.context, worker.config.Adapter.Rabbit.Crawler, nil)
	// Success
	return &worker
}

func (worker *cveCrawler) Start() {
	// Prepare
	worker.Prepare()
	group, ctx := errgroup.WithContext(worker.context)
	// Add Recent && Modified
	group.Go(func() error {
		// Recent
		configRecent := &model.NvdCve{
			Url:    fmt.Sprintf(defs.UrlNvdCveFeed, "recent"),
			Meta:   fmt.Sprintf(defs.UrlNvdCveMeta, "recent"),
			Status: defs.StatusDone,
			Target: "recent",
		}
		configRecent.GenID()
		if _, err := worker.mongo.CVEConfig().GetByID(ctx, configRecent.ID); err != nil {
			if err.Error() == mg.NotFoundError {
				if err := worker.mongo.CVEConfig().Store(ctx, configRecent); err != nil {
					return err
				}
			}
		}
		// Modified
		configModified := &model.NvdCve{
			Url:    fmt.Sprintf(defs.UrlNvdCveFeed, "modified"),
			Meta:   fmt.Sprintf(defs.UrlNvdCveMeta, "modified"),
			Status: defs.StatusDone,
			Target: "modified",
		}
		configModified.GenID()
		if _, err := worker.mongo.CVEConfig().GetByID(ctx, configModified.ID); err != nil {
			if err.Error() == mg.NotFoundError {
				if err := worker.mongo.CVEConfig().Store(ctx, configModified); err != nil {
					panic(err)
				}
			}
		}
		// Success
		return nil
	})
	// Collect URL
	group.Go(func() error {
		delay := clock.Hour * 6
		client := resty.New()
		client.SetTLSClientConfig(&tls.Config{InsecureSkipVerify: true})
		client.SetTimeout(time.Duration(clock.Minute * clock.Duration(worker.config.App.Timeout)))
		if worker.config.App.Proxy.Enable {
			client.SetProxy(worker.config.App.Proxy.String())
		}
		// Start
		for {
			now, _ := clock.Now(clock.UTC)
			year := now.Year()
			for y := defs.CveStartYear; y <= year; y++ {
				target := strconv.Itoa(y)
				config := &model.NvdCve{
					Url:    fmt.Sprintf(defs.UrlNvdCveFeed, target),
					Meta:   fmt.Sprintf(defs.UrlNvdCveMeta, target),
					Status: defs.StatusPending,
					Year:   y,
					Target: target,
				}
				config.GenID()
				_, err := worker.mongo.CVEConfig().GetByID(ctx, config.ID)
				if err != nil {
					if err.Error() != mg.NotFoundError {
						worker.logger.Errorf("[MG] Get CVE config error, reason: %v", err)
						continue
					}
					// Checker offline
					if _, err := os.Stat(config.GetZipFilePath()); os.IsNotExist(err) {
						// Check online
						resData, err := client.R().Head(config.Url)
						if err != nil || resData.StatusCode() != rest.StatusOK {
							worker.logger.Errorf("[REST] Head url %s error", config.Url)
							continue
						}
						resMeta, err := client.R().Head(config.Meta)
						if err != nil || resMeta.StatusCode() != rest.StatusOK {
							worker.logger.Errorf("[REST] Head url %s error", config.Meta)
							continue
						}
					}
					if err = worker.mongo.CVEConfig().Store(ctx, config); err != nil {
						worker.logger.Errorf("[MG] Insert CVE config error, reason: %v", err)
						continue
					}
					// Success
					worker.logger.Infof("add feed CVE(%d)", y)
				}
			}
			// Sleep
			now, _ = clock.Now(clock.UTC)
			next := now.Add(time.Duration(delay))
			worker.logger.Infof("next time collect: %s", clock.Format(next, clock.FormatHumanZ))
			clock.Sleep(delay)
		}
	})
	// Wait
	clock.Sleep(clock.Second * 30)
	// Collect
	group.Go(func() error {
		delay := clock.Minute * clock.Duration(worker.config.App.Schedule)
		for {
			for {
				configs, err := worker.mongo.CVEConfig().FindAll(ctx, &bson.M{"status": defs.StatusPending}, []string{"+year"})
				if err != nil {
					worker.logger.Errorf("get CVE configs error, reason: %v", err)
					continue
				}
				if len(configs) == 0 {
					break
				}
				// Crawl
				for _, config := range configs {
					// Check offline
					if _, err := os.Stat(config.GetZipFilePath()); os.IsNotExist(err) {
						// Crawl meta
						if err = worker.CrawlMeta(config); err != nil {
							worker.logger.Errorf("get meta (%s) error, reason: %v", config.Meta, err)
							continue
						}
						// Crawl data
						results, err := worker.CrawlData(config)
						if err != nil {
							worker.logger.Errorf("get data (%s) error, reason: %v", config.Url, err)
							continue
						}
						if err = worker.Process(config, results); err != nil {
							worker.logger.Errorf("get feed (CVE-%s) error, reason: %v", config.Target, err)
							continue
						}
					} else {
						now, _ := clock.Now(clock.UTC)
						config.Sum = defs.CveOffline
						config.Size = 0
						config.Last = now
						results, err := worker.Extract(config)
						if err != nil {
							worker.logger.Errorf("extract data (%s) error, reason: %v", config.GetZipFilePath(), err)
							continue
						}
						if err = worker.Process(config, results); err != nil {
							worker.logger.Errorf("get feed (CVE-%s) error, reason: %v", config.Target, err)
							continue
						}
					}
				}
			}
			// Crawl Recent
			recent, err := worker.mongo.CVEConfig().GetByID(ctx, hash.SHA1(fmt.Sprintf(defs.UrlNvdCveFeed, "recent")))
			if err != nil {
				worker.logger.Errorf("get CVE recent config error, reason: %v", err)
			} else {
				saved := *recent
				if err = worker.CrawlMeta(recent); err == nil {
					if saved.Sum != recent.Sum {
						// Crawl data
						if results, err := worker.CrawlData(recent); err == nil {
							if err = worker.Process(recent, results); err != nil {
								worker.logger.Errorf("get feed (CVE-%s) error, reason: %v", recent.Target, err)
							}
						} else {
							worker.logger.Errorf("get data (%s) error, reason: %v", recent.Url, err)
						}
					}
				} else {
					worker.logger.Errorf("get meta (%s) error, reason: %v", recent.Meta, err)
				}
			}
			// Modified
			modified, err := worker.mongo.CVEConfig().GetByID(ctx, hash.SHA1(fmt.Sprintf(defs.UrlNvdCveFeed, "modified")))
			if err != nil {
				worker.logger.Errorf("get CVE recent config error, reason: %v", err)
			} else {
				saved := *modified
				if err = worker.CrawlMeta(modified); err == nil {
					if saved.Sum != modified.Sum {
						// Crawl data
						if results, err := worker.CrawlData(modified); err == nil {
							if err = worker.Process(modified, results); err != nil {
								worker.logger.Errorf("get feed (CVE-%s) error, reason: %v", modified.Target, err)
							}
						} else {
							worker.logger.Errorf("get data (%s) error, reason: %v", modified.Url, err)
						}
					}
				} else {
					worker.logger.Errorf("get meta (%s) error, reason: %v", recent.Meta, err)
				}
			}
			// Sleep
			now, _ := clock.Now(clock.UTC)
			next := now.Add(time.Duration(delay))
			worker.logger.Infof("next time crawl: %s", clock.Format(next, clock.FormatHumanZ))
			clock.Sleep(delay)
		}
	})
}

func (worker *cveCrawler) Prepare() {
	if err := worker.queue.DeclareQueue(defs.QueueLogstashCveRaw, true, 0, 0); err != nil {
		panic(err)
	}
	if err := worker.queue.DeclareQueue(defs.QueueLogstashCveRawHistory, true, 0, 0); err != nil {
		panic(err)
	}
	if err := worker.queue.DeclareQueue(defs.QueueCveParser, true, 0, 0); err != nil {
		panic(err)
	}
}

func (worker *cveCrawler) Extract(config *model.NvdCve) ([]*model.CVERaw, error) {
	uz := unzip.New(config.GetZipFilePath(), fmt.Sprintf(defs.DefaultTempFolder, ""))
	if err := uz.Extract(); err != nil {
		worker.logger.Errorf("unzip file (%s) error, reason: %v", config.GetZipFilePath(), err)
		_ = os.Remove(config.GetZipFilePath())
		return nil, err
	}
	f, err := ioutil.ReadFile(config.GetJsonFilePath())
	if err != nil {
		worker.logger.Errorf("read file (%s) error, reason: %v", config.GetJsonFilePath(), err)
		return nil, err
	}
	defer os.Remove(config.GetJsonFilePath())
	results := make([]*model.CVERaw, 0)
	var data map[string]interface{}
	if err = json.Unmarshal(f, &data); err != nil {
		worker.logger.Errorf("unmarshal error, reason: %v", err)
		return nil, err
	}
	items, ok := data["CVE_Items"].([]interface{})
	if ok {
		for _, item := range items {
			bts, _ := json.Marshal(item)
			var result model.CVERaw
			if err = json.Unmarshal(bts, &result); err != nil {
				worker.logger.Errorf("unmarshal cve error, data: %s, reason: %v", string(bts), err)
				continue
			}
			results = append(results, &result)
		}
	}
	// Success
	return results, nil
}

func (worker *cveCrawler) Process(config *model.NvdCve, results []*model.CVERaw) error {
	totalData := len(results)
	totalErr := 0
	for _, result := range results {
		// Send logstash-cve-raw-queue
		meta := &model.CVERawLogstash{
			CVERaw: *result,
			Metadata: model.Metadata{
				ID:    result.GetID(),
				Index: defs.IndexCVERaw,
				Type:  defs.TypeCveRaw,
			},
		}
		metaBts, _ := json.Marshal(meta)
		if err := worker.queue.Publish("", defs.QueueLogstashCveRaw, rabbit.Message{
			Body:        metaBts,
			ContentType: rabbit.MIMEApplicationJSON,
			Mode:        rabbit.Persistent,
			Priority:    0,
		}); err != nil {
			totalErr += 1
			worker.logger.Errorf("send CVE (%s) to queue(%s) error, reason: %v", result.Detail.Metadata.ID, defs.QueueLogstashCveRaw, err)
			continue
		}
		// Send logstash-cve-raw-history-queue
		meta.Metadata.ID = hash.SHA1(fmt.Sprintf("%s--%s", result.GetID(), result.LastModifiedDate))
		meta.Metadata.Index = fmt.Sprintf(defs.IndexCVERawHistory, result.LastModifiedDate[:7])
		meta.Metadata.Type = defs.TypeCveRawHistory
		metaBts, _ = json.Marshal(meta)
		if err := worker.queue.Publish("", defs.QueueLogstashCveRawHistory, rabbit.Message{
			Body:        metaBts,
			ContentType: rabbit.MIMEApplicationJSON,
			Mode:        rabbit.Persistent,
			Priority:    0,
		}); err != nil {
			totalErr += 1
			worker.logger.Errorf("send CVE (%s) to queue(%s) error, reason: %v", result.Detail.Metadata.ID, defs.QueueLogstashCveRawHistory, err)
			continue
		}
		// Send cve-parser-queue
		dataBts, _ := json.Marshal(result)
		if err := worker.queue.Publish("", defs.QueueCveParser, rabbit.Message{
			Body:        dataBts,
			ContentType: rabbit.MIMEApplicationJSON,
			Mode:        rabbit.Persistent,
			Priority:    0,
		}); err != nil {
			totalErr += 1
			worker.logger.Errorf("send CVE (%s) to queue(%s) error, reason: %v", result.Detail.Metadata.ID, defs.QueueCveParser, err)
			continue
		}
	}
	// Save
	config.Total = totalData
	config.Error = totalErr
	config.Status = defs.StatusDone
	if err := worker.mongo.CVEConfig().UpdateOne(worker.context, config); err != nil {
		return err
	}
	worker.logger.Infof("get feed (CVE-%s): Total(%d), Error(%d)", config.Target, totalData, totalErr)
	// Success
	return nil
}

func (worker *cveCrawler) CrawlData(config *model.NvdCve) ([]*model.CVERaw, error) {
	client := resty.New()
	client.SetTLSClientConfig(&tls.Config{InsecureSkipVerify: true})
	client.SetTimeout(time.Duration(clock.Minute * clock.Duration(worker.config.App.Timeout)))
	if worker.config.App.Proxy.Enable {
		client.SetProxy(worker.config.App.Proxy.String())
	}
	res, err := client.R().SetOutput(config.GetZipFilePath()).Get(config.Url)
	if err != nil {
		worker.logger.Errorf("get url (%s) error, reason: %v", config.Url, err)
		return nil, err
	}
	if res.StatusCode() != rest.StatusOK {
		worker.logger.Errorf("get url (%s) return code %d", config.Url, res.StatusCode())
		return nil, errors.New(fmt.Sprintf("status code: %d", res.StatusCode()))
	}
	// Extract
	return worker.Extract(config)
}

func (worker *cveCrawler) CrawlMeta(config *model.NvdCve) error {
	client := resty.New()
	client.SetTLSClientConfig(&tls.Config{InsecureSkipVerify: true})
	client.SetTimeout(time.Duration(clock.Minute * clock.Duration(worker.config.App.Timeout)))
	if worker.config.App.Proxy.Enable {
		client.SetProxy(worker.config.App.Proxy.String())
	}
	res, err := client.R().Get(config.Meta)
	if err != nil {
		return err
	}
	if res.StatusCode() == rest.StatusOK {
		data := string(res.Body())
		data = strings.ReplaceAll(data, "\r", "")
		dataSplit := strings.Split(data, "\n")
		for _, item := range dataSplit {
			itemSplit := strings.Split(item, ":")
			if len(itemSplit) >= 2 {
				switch itemSplit[0] {
				case "lastModifiedDate":
					timeValue := strings.Join(itemSplit[1:], ":")
					if t, err := clock.ParseRFC3339(timeValue); err == nil {
						config.Last = t
					}
				case "size":
					if size, err := strconv.Atoi(itemSplit[1]); err == nil {
						config.Size = size
					}
				case "sha256":
					config.Sum = strings.ToLower(itemSplit[1])
				}
			}
		}
	} else {
		return errors.New(fmt.Sprintf("status code: %d", res.StatusCode()))
	}
	// Success
	return nil
}
